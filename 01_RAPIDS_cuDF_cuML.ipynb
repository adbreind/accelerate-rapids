{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAPIDS: Python-style Data Science on NVIDIA GPU\n",
    "\n",
    "RAPIDS requires Pascal (6.0) or higher CUDA compute capability\n",
    "\n",
    "What is CUDA compute capability? https://en.wikipedia.org/wiki/CUDA\n",
    "\n",
    "There's a grid on that page listing all of the details on models ... but effectively it means a GPU in the most recent generations of either gaming (GeForce), workstation (Quadro), server (Tesla), or embedded (Jetson/Tegra/DRIVE).\n",
    "\n",
    "We also need CUDA 9.2 or higher. How can we tell what we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "B0C8IV5TQnjN",
    "outputId": "5d96e036-e3fa-4306-a554-65c6592d782d"
   },
   "outputs": [],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9oOCJ4NYMjY7"
   },
   "source": [
    "# cuDF and cuML Smoke Test\n",
    "\n",
    "Let's make sure everything in installed and running correctly. (Installation instructions and docs are on the RAPIDS project page at https://rapids.ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "EwaJSKuswsNi",
    "outputId": "2c5534d2-e517-4674-852b-124f37c8a4e7"
   },
   "outputs": [],
   "source": [
    "import cudf\n",
    "\n",
    "gdf = cudf.DataFrame({'test':[1,2,3]})\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "dCE8WhO3HpL_",
    "outputId": "505aec19-8acd-4cbe-9b0e-a38bda9fb68c"
   },
   "outputs": [],
   "source": [
    "import cuml\n",
    "\n",
    "df_float = cudf.DataFrame()\n",
    "df_float['0'] = [1.0, 2.0, 5.0]\n",
    "df_float['1'] = [4.0, 2.0, 1.0]\n",
    "\n",
    "dbscan_float = cuml.DBSCAN(eps=1.0, min_samples=1)\n",
    "dbscan_float.fit(df_float)\n",
    "\n",
    "dbscan_float.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "nS7T-indP19Y",
    "outputId": "978cc86a-5e99-4912-d3bd-a2e63bbf6c64"
   },
   "outputs": [],
   "source": [
    "import cugraph\n",
    "\n",
    "G = cugraph.Graph()\n",
    "edges = cudf.DataFrame()\n",
    "edges['a'] = cudf.Series([0, 1, 2], dtype='int32')\n",
    "edges['b'] = cudf.Series([1, 2, 0], dtype='int32')\n",
    "G.from_cudf_edgelist(edges, source='a', destination='b')\n",
    "G.view_edge_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cABlcPbEl2dj"
   },
   "source": [
    "# Add GPU to Pandas-Style Analytics with cuDF\n",
    "\n",
    "## Beer Review Data Analysis\n",
    "\n",
    "Now that RAPIDS is maturing, it doesn't make as much sense to demo a handful of API features, or a use case made just to demo RAPIDS. The promise of RAPIDS is easily moving \"regular\" Python data science workflows to GPU, so today we are going to do exactly that. \n",
    "\n",
    "In this lab, I took on of my real Pandas workshop labs, and a dataset used in a recent popular O'Reilly conference, and challenged myself to run it unmodified -- as much as possible -- with RAPIDS.\n",
    "\n",
    "As we'll see, about 98% of the code is unchanged. If you know Pandas (or learn it) you'll know RAPIDS.\n",
    "\n",
    "Where I did run into APIs that haven't been implmented yet, instead of hiding that with a slick solution and letting you learn the hard way, I let them \"error out\" here so we could see together. And then I offered a workaround.\n",
    "\n",
    "Let's go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YczFxJov_vks"
   },
   "outputs": [],
   "source": [
    "import cudf\n",
    "\n",
    "df = cudf.read_csv('data/beer_small.csv')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "szIhoOFdmkhJ"
   },
   "source": [
    "How many reviews are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PSgtgvWr_wDq"
   },
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hEVuHpglmpua"
   },
   "source": [
    "How can we tell if there are missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aBuxeL_8_1EL"
   },
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XFeUtBwhmzAk"
   },
   "source": [
    "Since most reviews have data for most fields, let's drop the records with incomplete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fDvu2JFS_2e0"
   },
   "outputs": [],
   "source": [
    "df2 = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7CtQ0MDDm6Z1"
   },
   "outputs": [],
   "source": [
    "df2.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MpDFaemYm_uL"
   },
   "source": [
    "Let's get summary statistics for the numeric columns ... things like review score and ABV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HGrg_2hnm7bs"
   },
   "outputs": [],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7nC8dBxtnJy2"
   },
   "source": [
    "There are some really low-alcohol beers in there ... maybe even bogus data.\n",
    "\n",
    "Find all entries with ABV less than 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z1CcqFn8nF-i"
   },
   "outputs": [],
   "source": [
    "low_abv = df2[df2.beer_abv < 1]\n",
    "\n",
    "low_abv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9V3yyGMtniaG"
   },
   "source": [
    "How many of these reviews are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fgD-x03CnTY8"
   },
   "outputs": [],
   "source": [
    "len(low_abv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sUMswWNQnnWt"
   },
   "source": [
    "This includes multiple reviews for the same beer, so let's group by beer and count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lE07kGWRnlgD"
   },
   "outputs": [],
   "source": [
    "grouping = low_abv.groupby('beer_name')\n",
    "grouping.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_GJw0y9ko2vb"
   },
   "source": [
    "How consistent are the O'Douls overall scores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6IYu8cimnysJ"
   },
   "outputs": [],
   "source": [
    "scores = low_abv[low_abv.beer_name==\"O'Doul's\"]['review_overall']\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Eav0-yydpN3p"
   },
   "source": [
    "Let's plot a histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zvPHQoVno_Mv"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    scores.hist()\n",
    "except Exception as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ok, we've run into our first Pandas incompatibility__\n",
    "\n",
    "Happily, we can always convert `to_pandas()` if needed. Whether that makes sense depends on the task and the size of the data. Here we want to plot, so we can convert or -- if we are interested in the approximate distribution but not exact numbers -- we can downsample and plot. (Example of downsampling comes later.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "scores.to_pandas().hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9MfIBLAbpYSp"
   },
   "source": [
    "__Note:__ As RAPIDS evolves, it adds more and more Pandas compatibility, so definitely check back in the future and don't assume that if a feature is missing today that it won't arrive soon.\n",
    "\n",
    "---\n",
    "\n",
    "What are the mean and sd for the O'Doul's overall scores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Os6dqMgNpNAV"
   },
   "outputs": [],
   "source": [
    "scores.mean(), scores.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-_P9KB1ypl1y"
   },
   "source": [
    "In the full dataset, can we count reviews by brewery, and then by style within that brewery?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r0gVxucCpRxV"
   },
   "outputs": [],
   "source": [
    "df2.groupby(['brewery_name', 'beer_style']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "evW99OPdeGTi"
   },
   "source": [
    "### Now we'll try and build up a slightly more complex report\n",
    "\n",
    "Step 1: Find all rows corresponsing to reviews where the beer style starts with \"American\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KQ0I54mweRh_"
   },
   "outputs": [],
   "source": [
    "all_american = df2[df2.beer_style.str.startswith('American')]\n",
    "all_american"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zTSS1H1AecYd"
   },
   "source": [
    "Next, make a dataframe with just the `beer_style` and `review_overall` fields for those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H6HDs5WJejtj"
   },
   "outputs": [],
   "source": [
    "narrowed = all_american[['beer_style', 'review_overall']]\n",
    "narrowed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nE0CsERyeovC"
   },
   "source": [
    "Now we'll make a boxplot to capture the range and variance of the ratings. Pandas will do all the work if we call the built-in API. Look for it here: https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XdYvJnNv59F-"
   },
   "outputs": [],
   "source": [
    "narrowed.to_pandas().boxplot(by='beer_style', vert=False, figsize=(12,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add GPU to Scikit-Learn-Style Modeling with cuML\n",
    "\n",
    "As with the cuDF example, we'll start with a real Pandas + scikit-learn modeling exercise, and see if we can move it to RAPIDS with minimal effort.\n",
    "\n",
    "And, as before, if anything that didn't port over directly, I've allowed it to fail, and then offered a workaround."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: Diamonds\n",
    "\n",
    "This dataset of diamond sales (http://ggplot2.tidyverse.org/reference/diamonds.html) is of moderate size (~55,000 records) and resembles data records that occur in many business scenarios.\n",
    "\n",
    "For each of the diamond sales records, we have the following properties:\n",
    "* price: price in US dollars (\\\\$326-\\\\$18,823)\n",
    "* carat: weight of the diamond (0.2-5.01)\n",
    "* cut: quality of the cut (Fair, Good, Very Good, Premium, Ideal)\n",
    "* color: diamond colour, from J (worst) to D (best)\n",
    "* clarity: a measurement of how clear the diamond is (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best))\n",
    "* x: length in mm (0-10.74)\n",
    "* y: width in mm (0-58.9)\n",
    "* z: depth in mm (0-31.8)\n",
    "* depth: total depth percentage = z / mean(x, y) = 2 * z / (x + y) (43-79)\n",
    "* table: width of top of diamond relative to widest point (43-95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf \n",
    "\n",
    "df = cudf.read_csv('data/diamonds.csv')\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"unnamed\" column is a row number in the dataset. It turns out that this row number -- which sounds like it should be meaningless -- actually leaks key data about the diamonds. Why? It looks like that dataset is composed of merging 3 or more sets of records, was never shuffled, and some of those subsets were in price-ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demo the \"information leakage by row\" phenomenon, let's downsample the data (to make it easier to plot) and then graph row number against price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could sample using the Pandas call:\n",
    "\n",
    "`smaller_df = df.sample(frac=0.05)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But instead let's do it another way so we can see a RAPIDS highlight: on-GPU (\"on-device\") interop with datasets in other popular GPU accelerated tools, including PyTorch and CuPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy\n",
    "\n",
    "random_vals = cupy.random.rand(len(df))\n",
    "\n",
    "cudf.Series(random_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = cudf.Series(random_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df[mask < 0.0002]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = df[['Unnamed: 0', 'price']][mask < 0.05].to_pandas().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records.plot.scatter('Unnamed: 0', 'price', s=0.05, figsize=(10,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__OK, that worked!__ But we have a GPU ... surely that's the perfect device for high-volume rendering! \n",
    "\n",
    "We could use tools like Graphistry (part of RAPIDS: https://www.graphistry.com/ and https://github.com/graphistry/pygraphistry) to do that.\n",
    "\n",
    "---\n",
    "\n",
    "Let's get rid of the row number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.drop(df.columns[0], axis=1)\n",
    "\n",
    "df2[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Categorical Feautres__\n",
    "\n",
    "Now ... computers are good with numbers, but what about those words? (\"Premium\", \"Ideal\", etc.) It turns out that not only do we need to convert them to numbers, but we often want to do that in a way that treats them as totally separate properties.\n",
    "\n",
    "We'll consider the \"Ideal\"-ness of a diamond totally separately from the \"Premium\"-ness of that diamond, etc., and of course each diamond only has one of those properties. This is called \"one-hot encoding\" (or sometimes \"dummy variable encoding\" or \"one of k encoding\") and not always the right solution, but it's a common one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.cut.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.cut.value_counts().to_pandas().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = cudf.get_dummies(df2)\n",
    "\n",
    "df3.iloc[:3, 7:18]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll split out a \"test set\" -- remember we want to be able to evaluate the model on records that it hasn't seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.preprocessing.model_selection import train_test_split\n",
    "\n",
    "y = df3.price\n",
    "\n",
    "X = df3.drop(columns='price')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baselines\n",
    "\n",
    "In this case we'll use the mean price of the diamonds as a (constant) baseline model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our first \"baseline\" model just says for any diamond we might look at, its price is about $3900. Obviously this is usually going to be wrong, and often by a lot. But it's better than nother. Later we'll see how to compare a \"real\" model against this one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll set up a model. Let's start with something simple like kNN (k-nearest-neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`scikit-learn` code:__\n",
    "\n",
    "```python\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "neigh = KNeighborsRegressor(n_neighbors=5)\n",
    "model = neigh.fit(X_train, y_train) \n",
    "```\n",
    "\n",
    "And the RAPIDS code is a touch different, because it matches a more general `scikit` API, `NearestNeighbors` (https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html#sklearn.neighbors.NearestNeighbors) and we'll do the regression part ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.neighbors import KNeighborsRegressor\n",
    "\n",
    "nn = KNeighborsRegressor(n_neighbors=3)\n",
    "nn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inference (prediction) part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, how did we do?\n",
    "\n",
    "For regression problems like this, we'll measure the accuracy of our predictions using RMSE (root mean squared error). This is a measure of \"how wrong\" we typically are in our predictions, measured in the units we are predicting (i.e., in this case, dollars)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cuml.metrics import mean_squared_error\n",
    "\n",
    "np.sqrt(mean_squared_error(y_test.values, y_pred.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So is that actually any good?\n",
    "\n",
    "One way to get an idea is to compare it to the standard deviation of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Not bad__ ... it's pretty much what we \"should\" get for 3 nearest neighbors in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametric Model: Linear Regression\n",
    "\n",
    "The canonical example of a parametric model is a linear regression model. Linear regression -- which you might have done by hand on a small amount of data in high school or a college stats class -- is simple, fast, robust, and performs reasonably well for many kinds of real-world data.\n",
    "\n",
    "In fact, linear regression is one of the two or three most widely used algorithms in the world for data modeling.\n",
    "\n",
    "Here's a simple version with one predictor and one response plotted against each other, along with a regression line:\n",
    "\n",
    "<img src=\"images/gyP3KGA.png\">\n",
    "\n",
    "Since we're not doing a stats/ML class here, we'll skip the details on how we can fit a linear regression mathematically, and focus on comparing `scikit-learn` to RAPIDS for the task:\n",
    "\n",
    "Scikit code:\n",
    "```python\n",
    "from sklearn import linear_model\n",
    "\n",
    "lr = linear_model.LinearRegression()\n",
    "linear = lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = linear.predict(X_test)\n",
    "print(\"RMSE %f\" % np.sqrt(mean_squared_error(y_test, y_pred)) )\n",
    "```\n",
    "\n",
    "RAPIDS code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml import linear_model\n",
    "\n",
    "lr = linear_model.LinearRegression()\n",
    "\n",
    "reg = lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coefficients:\")\n",
    "print(reg.coef_)\n",
    "print(\"Intercept:\")\n",
    "print(reg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did we do? Let's predict for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lr.predict(X_test)\n",
    "\n",
    "print(\"Predictions:\")\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(y_test.values.astype('float64'), preds.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's exactly where we expect to end up for this data and model type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab: Powerplant Output \n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/combined+cycle+power+plant\n",
    "\n",
    "About the business problem: peaker plant operation\n",
    "\n",
    "What is in this dataset? Just under 10,000 observations of:\n",
    "\n",
    "* Temperature (AT) in the range 1.81°C and 37.11°C\n",
    "* Ambient Pressure (AP) in the range 992.89-1033.30 millibar,\n",
    "* Relative Humidity (RH) in the range 25.56% to 100.16%\n",
    "* Exhaust Vacuum (V) in the range 25.36-81.56 cm Hg\n",
    "* Net hourly electrical energy output (PE) 420.26-495.76 MW\n",
    "\n",
    "What is the goal? To model output (PE) based other measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cudf.read_csv('data/powerplant.csv')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to build a linear regression model for power output. (Hint: you can cut/paste a lot of the code we've already used in this notebook!)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "01-RAPIDS-cuDF-cuML-cuGraph.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
